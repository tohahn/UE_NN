\documentclass{article}
\usepackage{listings}
\usepackage[utf8]{inputenc}

\lstset{
	basicstyle=\footnotesize,
	numbers=left,
	tabsize=3,
	title=\lstname,
	breaklines=true
}

\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\title{Neuronale Netze - Übung 7}
\author{Tobias Hahn\\ 3073375}	
	
\begin{document}
\maketitle
\newpage
\section{Neuronales Netz}
\subsection{Implementierung}
Ich habe das Netz als untereinander verknotete Sammlung von Schichten implementiert. Der Vorwärts-, Rückwärts und Gewichtsanpassungsschritt werden von den Schichten ganz von selbst erledigt, man muss ihnen am Anfang nur die Daten und die Labels bereitstellen. Daneben gibt es eine Predict Methode, mit der man den Forwärtsschritt ohne Rückwärtsschritt und Gewichtsanpassung machen kann, wobei man entweder die vorhergesagten Ergebnisse oder die Fehler berechnen lassen kann - je nachdem ob man Labels mitgibt oder nicht.

\subsection{Code}
Der Code des Netzes ist hier:
\paragraph{}
\lstinputlisting[language=Python]{../code/NeuralNet.py}
\lstinputlisting[language=Python]{../code/train.py}

\subsection{Ergebnisse}
\begin{lstlisting}
# hidden nodes: 10 // Training error: 1.5951366864 // Test error: 25.2602785299
# hidden nodes: 20 // Training error: 0.00345100731381 // Test error: 20.2978443278
# hidden nodes: 30 // Training error: 0.0188063340479 // Test error: 23.1903266333
# hidden nodes: 40 // Training error: 0.047092620751 // Test error: 19.6124136129
# hidden nodes: 50 // Training error: 0.0295850736737 // Test error: 15.2657572425
# hidden nodes: 60 // Training error: 0.00615232677917 // Test error: 20.9680180911
# hidden nodes: 70 // Training error: 0.00389029399399 // Test error: 18.184484134
# hidden nodes: 80 // Training error: 0.00449535821462 // Test error: 16.6341676022
# hidden nodes: 90 // Training error: 0.0834084331233 // Test error: 19.677263485
# hidden nodes: 100 // Training error: 0.00195384190943 // Test error: 19.9208690295
# hidden nodes: 110 // Training error: 0.00440194332911 // Test error: 19.9072392755
# hidden nodes: 120 // Training error: 0.016182981848 // Test error: 16.8904571922
# hidden nodes: 130 // Training error: 0.00728166997087 // Test error: 17.6028740996
# hidden nodes: 140 // Training error: 0.00204702287436 // Test error: 14.677020486
# hidden nodes: 150 // Training error: 0.00935833008499 // Test error: 19.3108718565
# hidden nodes: 160 // Training error: 0.00299756302837 // Test error: 19.9936050608
# hidden nodes: 170 // Training error: 0.971229311966 // Test error: 16.5626160393
# hidden nodes: 180 // Training error: 0.00279814105182 // Test error: 13.9867308023
# hidden nodes: 190 // Training error: 0.00342643109315 // Test error: 16.936395778
\end{lstlisting}

\subsection{Interpretation}
Wie zu sehen ist änder sich der Error für eine ansteigende Anzahl an Knoten kaum. Auffallend ist, dass 10 Knoten wohl etwas zu wenig sind - hier ist der Fehler am Trainingset noch über 1. Anschließend aber schwankt der Fehler am Trainingset zwischen 1 und 0.002 hin und her, ohne irgendeine Tendenz, während der Fehler am Testset zwischen 23-15 hin und herschwankt, auch recht unbeeindruckt von der Anzahl der verdeckten Knoten. Dies deutet darauf hin dass zwischen 10 und 20 verdeckten Knoten genügen, um alle interessanten Features die man mit einer verdeckten Schicht entdecken kann abzudecken. Versuche mit mehreren verdeckten Schichten ergaben dass die das Ergebnis auch nicht merkbar verbesserten.

\end{document}
